#+startup: Num
#+TITLE: Time Series: Defining a Search Engine
#+AUTHOR: Philipp Beer
#+EMAIL: beer.p@live.unic.ac.cy
#+OPTIONS: toc:nil
#+OPTIONS: num:1
#+LATEX_HEADER: \usepackage[margin=2.5cm]{geometry}
#+LATEX_HEADER: \usepackage[font=small, labelfont=bf, margin=1cm]{caption}
#+LATEX_CLASS_OPTIONS: [hidelinks,11pt]
#+PROPERTY: header-args :exports none :tangle "~Dropbox/bibliography/593_thesis.bib"
#+LATEX_HEADER: \usepackage[natbib=true,citestyle=ieee, maxcitenames=2, mincitenames=1]{biblatex} \DeclareFieldFormat{apacase}{#1} \addbibresource{~/Dropbox/bibliography/593_thesis.bib}

* Thesis: Time Series Search Engine
** Purpose
The purpose of this thesis is to explore the possibility of creating a time series series search engine.

** Introduction

Time series is often described as "anything that is observed sequentially over time" which usually are observed at regular intervals of time cite:hyndman2014forecasting. They can be described as collection of observations that are considered together in chronological order rather than as individual values or a multiset of values. Their representation can be described as ordered pairs:
$S = (s_1,s_2,\dots,s_n)$ where $s_n = (t_n,v_n)$. $t_n$ can be a date, timestamp or any other element that defines order. $v_1$ represents the observation at that position in the time series.

Time series are utilized to analyze and gain insight from historic events/patterns with respect to the observational variable(s) and their interactions. A second area of application is forecasting. Here time series are utilized to predict the observations that occur in future under the assumption that the historic information can provide insight into the behavior of the observed variables.

citeauthor:Fu_2011 in their work cite:Fu_2011 categorized time series research into (1) representation, (2) indexing, (3) similarity measure, (4) segmentation, (5) visualization and (6) mining. Research in these different fields started taking off in the second half of the 20^th century. For example in cite:_str_m_1969 the authors worked on questions of representation via sampling the sampling of time series in citeyear:_str_m_1969. All these different research areas always have to deal with the challenges that inhibit time series data. Time series data incorporates the similar obstacles as high dimensional data, namely the "curse of dimensionality" cite:Tang_2019 and requiring large computational efforts in order to generate insights.

*** Applications
Time series are encountered everywhere. Any metric that is captured over time can utilized as time series. Granularity can be used as descriptor for the sampling rate of a series or more general how often measurements for a particular metric are taken. This granularity has a tendency to increase as well. As example consumer electronics that capture health and fitness data can mentioned. Or sensors which are utilized in the automotive industry or heavy machinery where they are employed to capture information for predictive maintenance applictions.

In the financial industry time series are a very fundamental component of decision making, like the development of stock prices over time or financial metrics of interest. The same is true for macro economic information or metrics concerning social structures in society, etc.

In the medical field time series are also ubiquitous. Whether they relate to patient date like blood pressure. The bio statistics field utilizes electrographical data like electrocardiography, electroencephalography and many others. In more aggregate medical analysis like toxicology analysis of drug treatments for vaccine approvals they are utilized and in many forms of risk management, for example, population level obesity levels.

In engineering fields the utilization is often times similar to the above but it also require that information that is captured in time series is transferred between locations in an efficient manner. For example voice calls are required to be transferred between the participants in a fast manner and with minimized levels of noise in the data. Another interesting industrial example in the biomedical technology field is Neuralink which aims to implement a brain-machine-interface (BMI) utilizing mobile hardware like smartphones as the basis for its computation. Here a large of amount of time series data is generated which requires quick processing to generate real-time information. citeauthor:Musk_2019 describes a recording system with 3072 electrodes generating time series data cite:Musk_2019 that is used to capture the brain information and visualized in real-time cite:Siegle_2017.

Time series data is paramount to a wide variety of areas, relating to many different fields. Looking at the trajectorty it seems likely that going forward more time series data on a higher granularity will be generated. This in turn increases the need to be able process, analyze, compare and respond to the data with methods that are faster than today's standard options.

*** Focus
In this work we focus on allowing the comparison of time series generated from different processes with different underlying properties and introduce a new measure of similarity. Our method does not require assumptions on the utilized time series and requires significantly less computaional resources for the execution of the comparison.

*** Organization of this theis
The rest of this thesis is organized as follows.

*** TODO to be integrated
- refer to previous work on measures of similarity and outcome
- measure of similarity required
- challenges with time series (domains, granularity, length, outliers)
- area of signal processing interesting methods



  
** Exisiting work

Time series share the same challenges as other high dimensional data in that it quickly requires high computational power to process them and they suffer from the "curse of dimensionality" cite:Tang_2019.

*** Measuring similarity
# integrate section 3.3 in for similarity measures
In order to be able to describe the closeness of time series or multiple time series to each a measure for similarity is required. In the literature various general measures and corresponding computation methods can be found. citeauthor:Wang_2012 reviewed time series measures and categorized the similarity measures into 4 categories: (1) lock-step measures, (2) elastic measures, (3) threshold-based measures, and (4) pattern-based measures.\\

*Lockstep-measures* include the L_p-norms (Manhatten and Euclidean Distance) as well as Dissimilarity Measure (DISSIM). *Elastic measures* include metrics like Dynamic Time Warping (DTW) and edit distance based measures like Longest Common Subsequence (LCSS), Edit Sequence on Real Sequence (EDR), Swale and Edit Distance with Real Penalty. An example for *threshold-based measures* are threshold query based similarity search (TQuEST). And Spatial Assembling Distance (SpADe) is an example for pattern-based measures.

**** Euclidean Distance
Euclidean Distance is the most widely used distance metric in the research of time series. (add list of papers here)

- explain advantages

- mention shortcomings
  - same length period

  - handling of outliers and noise

  - handling of stretching of series

  - computational complexity


**** Dynamic Time Warping
- invented by cite:Berndt94usingdynamic in 1994
- warp series by computing the distance from one point to all other points in the other series and define a warped path that minimizes the distance
  #+BEGIN_EXPORT latex
  \begin{equation}
  DTW(S_a,S_b) = min\{\sqrt{\sum_{k=1}^P \delta{(\omega_k)}}
  \end{equation}
  #+END_EXPORT
  
- advantages: handles distortions, does not require same length ts
- disadvantages: outliers may create a false impression of similarity, computaional complexity of $O(n^2)$ makes utilization for very long time series impractical and comparison with large sets of time series is also very time intensive

**** Similarity through decomposition
- introduce time series decomposition (reference in cite:hyndman2014forecasting)
- trend and seasonality (mention assumptions about period)
*** Time series representation
- Principal Component Analysis
- SAX
- Discrete Fourier Transform (DFT) and Discrete Wavelet Transform (DWT)
  - mention origin in signal processing and ubiquitous use in engineering (image and audio compression)

*** Challenges when building a time series
- length of series
- trend
- seasonality
- computational complexity -> issue because of data size
- granularity or sampling rates
- noise
- data quality
- similarity is task dependent (level)
- usual need for preprocessing the time series data (denoising, detrending, amplitude scaling) -> any pre-processing does modify the series

*** Data Analysis
what does M4 data look like
*** Challenges
- How many frequencies to compare?
- priorities of frequencies (power spectrum)
- different length of time series (leading to different  frequencies) - ranges solved with logs
** Methodology
*** Used Data
The research in time series has been numerous and focused on various properties of them as well as finding methods to accurately predict them. Aside of forecasting ell researched areas are measures of similarity and retrieval of time series.

**** Forecasting
In the arena of forecasting the M-competition organized by Prof. Makridakis played a big role in the development of forecasting methods shortly after their inception in 1979.
# add paper and verify dates
One of the aspects that has been correct up until the 5th installment of the M-competition is that statistical methods in forecasting have outperformed more complex machine learning methods. So learning algorithms did not benefit sufficiently from learning from multiple series to generate more accurate point predictions and prediction intervals compared to the statistics-based alternatives.

One interesting question in this area is whether clustering of time series that have similar properties and training algorithms per cluster of "similar" series can help simplify the learning process for machine learning methods and in consequence improve their performance in future competitions.

# reference to relevant chapter
However, expressing similarity for time series is a challenging questions with respect to which metrics to utilize, computational complexity as well as limiting assumptions that need to be made for time series.

*** Main contribution of the thesis
- transformation into Fourier-space
- transfer frequencies into frequency range band with increasing range width (using log scale)
- computation of frequency energy levels (sort and keep top 5) -> ask Prof. how to name this parameter
- conversion of ordered frequencies into frequency range band
- for each series to compare -> compare whether the frequency matches on the ordered positions -> provide exponential value per position -> match on more powerful frequencies is valued higher
*** additional computations
- utilization of FFT utilizes only frequency space (future work should consider comparison of energy levels per frequency)
- additional simple statistics computed (mean, std, quantiles)
- ts decomposition for trend estimation (requires parameter for period) -> then best line fit for slope of the time series
- computation of deltas for each series to search with statistics and slope of all other time series (review computational complexlity)
- ranking of matching series based highest frequency range match and ONE statistic
***  Preprocessing
- M4 data wide format vs. long format
*** Parallelization
- computation times
- scalability
- Samples for results only (stratification vs. non-stratification)
**** Threads vs. Processes

*** Technology (check with Prof. if required)
R vs. Python vs. Mathematica, Matlab
*** 
- load
- transform to FFT vector space
- compare most important frequencies
- compare candidates
- select winner (which criteria)
** Exploratory Data Study
- what do results look like
** Formal Evaluation
- (maybe ) improvement in forecasting approach
- find dataset with ground truth and compare DTW to this approach
- Distance metrics
- computational complexity
** Conclusion & future work
*** Successes
*** Failures
*** Flaws
- final computation
*** What is missing
- denoising of time series
- adjustment of number of frequencies used
-
** Results & Discussion
** References
#+LATEX: \printbibliography[heading=none]
